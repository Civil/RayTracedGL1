// Copyright (c) 2021 Sultim Tsyrendashiev
// 
// Permission is hereby granted, free of charge, to any person obtaining a copy
// of this software and associated documentation files (the "Software"), to deal
// in the Software without restriction, including without limitation the rights
// to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
// copies of the Software, and to permit persons to whom the Software is
// furnished to do so, subject to the following conditions:
// 
// The above copyright notice and this permission notice shall be included in all
// copies or substantial portions of the Software.
// 
// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
// SOFTWARE.
// 
// Copyright (c) 2018, Christoph Schied
// All rights reserved.
// 
// Redistribution and use in source and binary forms, with or without
// modification, are permitted provided that the following conditions are met:
//     * Redistributions of source code must retain the above copyright
//       notice, this list of conditions and the following disclaimer.
//     * Redistributions in binary form must reproduce the above copyright
//       notice, this list of conditions and the following disclaimer in the
//       documentation and/or other materials provided with the distribution.
//     * Neither the name of the Karlsruhe Institute of Technology nor the
//       names of its contributors may be used to endorse or promote products
//       derived from this software without specific prior written permission.
// 
// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
// ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
// WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
// DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY
// DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
// (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
// LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
// ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

#version 460

// "Spatiotemporal Variance-Guided Filtering: Real-Time Reconstruction for Path-Traced Global Illumination", C.Schied et al.
// 4.3 Edge-avoiding a-trous wavelet transform

// This file is a copy of CmSVGFAtrous.comp
// It contains an optimized implementation for specific iteration.

#define DESC_SET_FRAMEBUFFERS 0
#define DESC_SET_GLOBAL_UNIFORM 1
#include "ShaderCommonGLSLFunc.h"

layout(local_size_x = COMPUTE_SVGF_ATROUS_GROUP_SIZE_X, local_size_y = COMPUTE_SVGF_ATROUS_GROUP_SIZE_X, local_size_z = 1) in;

layout (constant_id = 0) const uint atrousIteration = 0;

const int STEP_SIZE = 1 << atrousIteration;
const float SIGMA_LUMINANCE = 4.0;
// 3x3 box filter
const int FILTER_RADIUS = 1;
const float WAVELET_KERNEL[2][2] = 
{
    { 1.0, 0.5  },
    { 0.5, 0.25 }
};


// TODO: pack color values
struct AtrousData
{
    vec3    directDiffuseColor;
    vec3    specularColor;
    float   roughness;
    uint    encNormalGeometry;
    float   depth;
    float   gradDepth;
};

// Preloaded data for filter pixel data. Additional FILTER_RADIUS pixels at both ends for each dimension
const int SHARED_WIDTH = FILTER_RADIUS + COMPUTE_SVGF_ATROUS_GROUP_SIZE_X + FILTER_RADIUS;
shared AtrousData atrousData[SHARED_WIDTH][SHARED_WIDTH];
shared float directDiffuseVariance[SHARED_WIDTH][SHARED_WIDTH];


void fillFilterData(
    sampler2D samplerDiff, 
    sampler2D samplerSpec, 
    sampler2D samplerIndirR, sampler2D samplerIndirG, sampler2D samplerIndirB, 
    const ivec2 globalBasePix, const int sharedOffset)
{
    const ivec2 sharedPix = ivec2(sharedOffset % SHARED_WIDTH, sharedOffset / SHARED_WIDTH);
    const ivec2 globalPix = globalBasePix + sharedPix;

    AtrousData data;
    
    const vec3 dg = texelFetch(framebufDepth_Sampler, globalPix, 0).rgb;
    data.depth = dg.r;
    data.gradDepth = length(dg.gb); // changed dot to length, to remove vertical/horizontal artifacts

    const vec4 cv           = texelFetch(samplerDiff,                       globalPix, 0);
    data.directDiffuseColor = cv.rgb;
    directDiffuseVariance[sharedPix.y][sharedPix.x] = cv.a;
    
    //data.indirectDiffuseSH  = texelFetchSH(samplerIndirR, samplerIndirG, samplerIndirB, globalPix);
    data.roughness          = texelFetch(framebufMetallicRoughness_Sampler, globalPix, 0).g;
    data.specularColor      = texelFetch(samplerSpec,                       globalPix, 0).rgb;
    data.encNormalGeometry  = texelFetchEncNormalGeometry(                  globalPix);     

    atrousData[sharedPix.y][sharedPix.x] = data;
}


void preload(
    sampler2D samplerDiff, 
    sampler2D samplerSpec, 
    sampler2D samplerIndirR, sampler2D samplerIndirG, sampler2D samplerIndirB)
{
    const ivec2 globalBasePix = ivec2(gl_WorkGroupID.xy) * COMPUTE_SVGF_VARIANCE_GROUP_SIZE_X - ivec2(FILTER_RADIUS);
    const int threadIndex = int(gl_LocalInvocationIndex);

    const int sharedCount = SHARED_WIDTH * SHARED_WIDTH;
    const int threadCount = COMPUTE_SVGF_VARIANCE_GROUP_SIZE_X * COMPUTE_SVGF_VARIANCE_GROUP_SIZE_X;
   
    // how many threads should load only one pixel
    const int oneLoadCount = 2 * threadCount - sharedCount;
    // how many threads should load two pixels
    // const int twoLoadCount = sharedCount - threadCount;

    if (threadIndex < oneLoadCount)
    {
        // first threads need to preload only 1 pixel
        fillFilterData(
            samplerDiff, samplerSpec, samplerIndirR, samplerIndirG, samplerIndirB,
            globalBasePix, threadIndex);
    }
    else
    {
        // now threads are loading 2 neighboring pixels
        const int neighborsIndex = threadIndex - oneLoadCount;

        fillFilterData(
            samplerDiff, samplerSpec, samplerIndirR, samplerIndirG, samplerIndirB,
            globalBasePix, oneLoadCount + neighborsIndex * 2 + 0);
       
        fillFilterData(
            samplerDiff, samplerSpec, samplerIndirR, samplerIndirG, samplerIndirB,
            globalBasePix, oneLoadCount + neighborsIndex * 2 + 1);
    }
}

#define GET_ATROUS_DATA(offsetX, offsetY) (atrousData[gl_LocalInvocationID.y + FILTER_RADIUS + offsetY][gl_LocalInvocationID.x + FILTER_RADIUS + offsetX])
#define GET_DIR_DIFF_VARIANCE(offsetX, offsetY) (directDiffuseVariance[gl_LocalInvocationID.y + FILTER_RADIUS + offsetY][gl_LocalInvocationID.x + FILTER_RADIUS + offsetX])


float prefilterLuminanceVariance()
{
    const int GaussianFilterRadius = 1;
    const float gaussianKernel[2][2] = 
    {
        { 1.0 / 4.0, 1.0 / 8.0  },
        { 1.0 / 8.0, 1.0 / 16.0 }
    };

    float r = 0;

    for (int yy = -GaussianFilterRadius; yy <= GaussianFilterRadius; yy++)
    {
        for (int xx = -GaussianFilterRadius; xx <= GaussianFilterRadius; xx++)
        {
            const float variance = GET_DIR_DIFF_VARIANCE(xx, yy);
            const float w = gaussianKernel[abs(xx)][abs(yy)];

            r += variance * w;
        }
    }

    return sqrt(max(r, 0.0));
}


float dotEnc(uint n1, uint n2)
{
    return dot(decodeNormal(n1), decodeNormal(n2));
}


void atrous0(
    sampler2D samplerIndirR, sampler2D samplerIndirG, sampler2D samplerIndirB,
    out vec3 outDiff, out float outVariance, 
    out vec3 outSpec,
    out SH outIndirSH)
{
    const ivec2 pix = ivec2(gl_GlobalInvocationID);
    const ivec2 screenSize = ivec2(globalUniform.renderWidth, globalUniform.renderHeight);


    const AtrousData center = GET_ATROUS_DATA(0, 0);


    if (center.depth < 0.0 || center.depth > MAX_RAY_LENGTH)
    {
        return;
    }

    outVariance = GET_DIR_DIFF_VARIANCE(0, 0);
    outDiff     = center.directDiffuseColor;
    outSpec     = center.specularColor;
    outIndirSH  = texelFetchSH(samplerIndirR, samplerIndirG, samplerIndirB, pix);

    const float l = getLuminance(outDiff);
    const float wLumMultiplier = 1.0 / (SIGMA_LUMINANCE * prefilterLuminanceVariance() + 0.00001);
   
    // the rougher the surface, the more blur to apply
    const float wRoughMultiplier = pow(center.roughness, STEP_SIZE);

    const float gradDepth = center.gradDepth;


    float weightSum = 1.0;
    float weightSumSpec = 1.0;
    float weightSumIndir = 1.0;

    [[unroll]]
    for (int yy = -FILTER_RADIUS; yy <= FILTER_RADIUS; yy++)
    {
        for (int xx = -FILTER_RADIUS; xx <= FILTER_RADIUS; xx++)
        {
            if (xx == 0 && yy == 0)
            {
                continue;
            }

            const ivec2 offset = ivec2(xx * STEP_SIZE, yy * STEP_SIZE);
            const ivec2 pix_q = pix + offset;


            const AtrousData other = GET_ATROUS_DATA(offset.x, offset.y);


            const float l_q = getLuminance(other.directDiffuseColor);

            const float w_z = abs(center.depth - other.depth) / max(gradDepth * (abs(xx) + abs(yy)), 0.01);
            const float w_n = pow(max(0.0, dotEnc(center.encNormalGeometry, other.encNormalGeometry)), 128.0);
            const float w_l = abs(l - l_q) * wLumMultiplier;

            // larger weight if roughness difference is small
            const float w_r = min(pow(1.025 - abs(center.roughness - other.roughness), 32), 1.0) * wRoughMultiplier;

            const float waveletW = WAVELET_KERNEL[abs(yy)][abs(xx)];
            const float isInside = float(testInside(pix_q, screenSize));

            const float wBase = exp(-w_z * w_z) * w_n * waveletW * isInside;

            const float wDiff      = wBase * exp(-w_l);
            const float wSpec      = wBase * w_r;
            const float wDiffIndir = wBase;


            outDiff += other.directDiffuseColor * wDiff;
            outSpec += other.specularColor * wSpec;
            // SH are fetched here, because storing it in shared memory causes short scoreboard stalls
            accumulateSH(outIndirSH, texelFetchSH(samplerIndirR, samplerIndirG, samplerIndirB, pix_q), wDiffIndir);

            outVariance += GET_DIR_DIFF_VARIANCE(offset.x, offset.y) * wDiff * wDiff;

            weightSum += wDiff;
            weightSumSpec += wSpec;
            weightSumIndir += wDiffIndir;
        }
    }

    const float invWeightSum = 1.0 / weightSum;
    const float invWeightSumSpec = 1.0 / weightSumSpec;
    const float invWeightSumIdir = 1.0 / weightSumIndir;

    outDiff     *= invWeightSum;
    outVariance *= invWeightSum * invWeightSum;
    outSpec     *= invWeightSumSpec;
    multiplySH(outIndirSH, invWeightSumIdir);
}


void main()
{
    ivec2 pix = ivec2(gl_GlobalInvocationID);


    preload(
        framebufDiffPingColorAndVariance_Sampler, 
        framebufSpecPingColor_Sampler,
        framebufIndirPingSH_R_Sampler, framebufIndirPingSH_G_Sampler, framebufIndirPingSH_B_Sampler);
    barrier();


    if (pix.x >= uint(globalUniform.renderWidth) || pix.y >= uint(globalUniform.renderHeight))
    {
        return;
    }


    float updatedVariance = 0.0;
    vec3 filteredDiff = vec3(0.0);
    vec3 filteredSpec = vec3(0.0);
    SH filteredIndir  = newSH();


    atrous0(
        framebufIndirPingSH_R_Sampler, framebufIndirPingSH_G_Sampler, framebufIndirPingSH_B_Sampler,
        filteredDiff, updatedVariance, filteredSpec, filteredIndir); 


    // for the first iteration, save to color history buffer for temporal accumulation
    imageStore(framebufDiffColorHistory,         pix, vec4(filteredDiff, updatedVariance)); 
    imageStore(framebufSpecPongColor,            pix, vec4(filteredSpec, 0.0)); 
    imageStoreIndirPongSH(                       pix, filteredIndir); 
}


#if COMPUTE_SVGF_ATROUS_ITERATION_COUNT != 4
    #error Atrous is implemented for 4 iterations 
#endif