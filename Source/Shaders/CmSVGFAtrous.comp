// Copyright (c) 2021 Sultim Tsyrendashiev
// 
// Permission is hereby granted, free of charge, to any person obtaining a copy
// of this software and associated documentation files (the "Software"), to deal
// in the Software without restriction, including without limitation the rights
// to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
// copies of the Software, and to permit persons to whom the Software is
// furnished to do so, subject to the following conditions:
// 
// The above copyright notice and this permission notice shall be included in all
// copies or substantial portions of the Software.
// 
// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
// SOFTWARE.
// 
// Copyright (c) 2018, Christoph Schied
// All rights reserved.
// 
// Redistribution and use in source and binary forms, with or without
// modification, are permitted provided that the following conditions are met:
//     * Redistributions of source code must retain the above copyright
//       notice, this list of conditions and the following disclaimer.
//     * Redistributions in binary form must reproduce the above copyright
//       notice, this list of conditions and the following disclaimer in the
//       documentation and/or other materials provided with the distribution.
//     * Neither the name of the Karlsruhe Institute of Technology nor the
//       names of its contributors may be used to endorse or promote products
//       derived from this software without specific prior written permission.
// 
// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
// ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
// WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
// DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY
// DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
// (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
// LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
// ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

#version 460

// "Spatiotemporal Variance-Guided Filtering: Real-Time Reconstruction for Path-Traced Global Illumination", C.Schied et al.
// 4.3 Edge-avoiding a-trous wavelet transform

#define DESC_SET_FRAMEBUFFERS 0
#define DESC_SET_GLOBAL_UNIFORM 1
#include "ShaderCommonGLSLFunc.h"

layout(local_size_x = COMPUTE_SVGF_GROUP_SIZE_X, local_size_y = COMPUTE_SVGF_GROUP_SIZE_Y, local_size_z = 1) in;

layout (constant_id = 0) const uint atrousIteration = 0;

const int StepSize = 1 << atrousIteration;

const float SigmaLuminance = 4.0;

float prefilterLuminanceVariance(sampler2D samplerColor, const ivec2 pix, const float pixVariance)
{
    const int GaussianFilterSize = 1;
    const float gaussianKernel[2][2] = 
    {
        { 1.0 / 4.0, 1.0 / 8.0  },
        { 1.0 / 8.0, 1.0 / 16.0 }
    };

    float r = pixVariance * gaussianKernel[0][0];

    for (int yy = -GaussianFilterSize; yy <= GaussianFilterSize; yy++)
    {
        for (int xx = -GaussianFilterSize; xx <= GaussianFilterSize; xx++)
        {
            if (xx != 0 || yy != 0)
            {
                const float variance = texelFetch(samplerColor, pix + ivec2(xx, yy), 0).a;
                const float w = gaussianKernel[abs(xx)][abs(yy)];

                r += variance * w;
            }
        }
    }

    return sqrt(max(r, 0.0));
}

void atrous(sampler2D samplerDiff, sampler2D samplerSpec, out vec3 outDiff, out float outVariance, out vec3 outSpec)
{
    const ivec2 pix = ivec2(gl_GlobalInvocationID);
    const ivec2 screenSize = ivec2(globalUniform.renderWidth, globalUniform.renderHeight);

    const vec4 cv = texelFetch(samplerDiff, pix, 0);
    outDiff       = cv.rgb;
    outVariance   = cv.a;

    outSpec       = texelFetch(samplerSpec, pix, 0).rgb;

    const vec3 dg = texelFetch(framebufDepth_Sampler, pix, 0).rgb;
    const float depth     = dg.r;
    const vec2  gradDepth = dg.gb;

    if (depth < 0.0)
    {
        return;
    }
    
    const vec3 normal = texelFetch(framebufNormalGeometry_Sampler, pix, 0).rgb;

    const float l = getLuminance(outDiff);
    const float wLumMultiplier = 1.0 / (SigmaLuminance * prefilterLuminanceVariance(samplerDiff, pix, outVariance) + 0.00001);
   
    // the rougher the surface, the more blur to apply
    const float roughness = texelFetch(framebufMetallicRoughness_Sampler, pix, 0).g;
    const float wRoughMultiplier = pow(roughness, StepSize);

    float weightSum = 1.0;
    float weightSumSpec = 1.0;

    const int FilterSize = 1;
    const float waveletKernel[2][2] = 
    {
        { 1.0, 0.5  },
        { 0.5, 0.25 }
    };

    for (int yy = -FilterSize; yy <= FilterSize; yy++)
    {
        for (int xx = -FilterSize; xx <= FilterSize; xx++)
        {
            if (xx == 0 && yy == 0)
            {
                continue;
            }

            const ivec2 offset = ivec2(xx * StepSize, yy * StepSize);
            const ivec2 pix_q = pix + offset;

            const float roughness_q = texelFetch(framebufMetallicRoughness_Sampler, pix_q, 0).g;
            const vec3  normal_q    = texelFetch(framebufNormalGeometry_Sampler,    pix_q, 0).rgb;
            const float depth_q     = texelFetch(framebufDepth_Sampler,             pix_q, 0).r;

            const vec3  specColor_q = texelFetch(samplerSpec,                       pix_q, 0).rgb;
            
            const vec4  cv_q        = texelFetch(samplerDiff,                       pix_q, 0);
            const vec3  diffColor_q = cv_q.rgb;
            const float variance_q  = cv_q.a;
            const float l_q         = getLuminance(diffColor_q);

            const float w_z = abs(depth - depth_q) / max(dot(gradDepth, vec2(offset)), 0.01);
            const float w_n = pow(max(0.0, dot(normal, normal_q)), 128.0);
            const float w_l = abs(l - l_q) * wLumMultiplier;

            // larger weight if roughness difference is small
            const float w_r = min(pow(1.025 - abs(roughness - roughness_q), 32), 1.0) * wRoughMultiplier;

            const float waveletW = waveletKernel[abs(yy)][abs(xx)];
            const float isInside = float(testInside(pix_q, screenSize));

            const float wDiff = exp(-w_z - w_l) * w_n * waveletW * isInside;
            const float wSpec = w_r * exp(-w_z) * w_n * waveletW * isInside;

            outDiff += diffColor_q * wDiff;
            outSpec += specColor_q * wSpec;

            outVariance += variance_q * wDiff * wDiff;

            weightSum += wDiff;
            weightSumSpec += wSpec;
        }
    }

    outDiff     /= weightSum;
    outVariance /= weightSum * weightSum;
    outSpec     /= weightSumSpec;
}

void main()
{
    ivec2 pix = ivec2(gl_GlobalInvocationID);

    if (pix.x >= uint(globalUniform.renderWidth) || pix.y >= uint(globalUniform.renderHeight))
    {
        return;
    }

    vec3 filteredDiff;
    vec3 filteredSpec;
    float updatedVariance;

    switch (atrousIteration)
    {
        case 0: atrous(framebufDiffPingColorAndVariance_Sampler, framebufSpecPingColor_Sampler, filteredDiff, updatedVariance, filteredSpec); break;
        case 1: atrous(framebufDiffColorHistory_Sampler,         framebufSpecPongColor_Sampler, filteredDiff, updatedVariance, filteredSpec); break;
        case 2: atrous(framebufDiffPingColorAndVariance_Sampler, framebufSpecPingColor_Sampler, filteredDiff, updatedVariance, filteredSpec); break;
        case 3: atrous(framebufDiffPongColorAndVariance_Sampler, framebufSpecPongColor_Sampler, filteredDiff, updatedVariance, filteredSpec); break;
    }

    // for the first iteration, save to color history buffer for temporal accumulation
    switch (atrousIteration)
    {
        case 0: imageStore(framebufDiffColorHistory,         pix, vec4(filteredDiff, updatedVariance)); 
                imageStore(framebufSpecPongColor,            pix, vec4(filteredSpec, 0.0)); 
                break;
        case 1: imageStore(framebufDiffPingColorAndVariance, pix, vec4(filteredDiff, updatedVariance)); 
                imageStore(framebufSpecPingColor,            pix, vec4(filteredSpec, 0.0)); 
                break;
        case 2: imageStore(framebufDiffPongColorAndVariance, pix, vec4(filteredDiff, updatedVariance)); 
                imageStore(framebufSpecPongColor,            pix, vec4(filteredSpec, 0.0)); 
                break;
    }

    if (atrousIteration == 3)
    {
        const vec3 albedo        = texelFetch(framebufAlbedo_Sampler, pix, 0).rgb;
        const float depth        = texelFetch(framebufDepth_Sampler,  pix, 0).r;
        
        if (depth > MAX_RAY_LENGTH)
        {
            imageStore(framebufFinal, pix, vec4(albedo, 0));
            return;
        }

        const vec3 diffuse       = filteredDiff;
        const vec3 specular      = filteredSpec;
        const vec3 indirect      = vec3(0.0); // texelFetch(framebufUnfilteredIndirect_Sampler, pix, 0).rgb;
        const float surfMetallic = texelFetch(framebufMetallicRoughness_Sampler,  pix, 0).r;
        
        const vec3 light = (diffuse + indirect) * (1 - surfMetallic) + specular * surfMetallic;
        const vec3 color = albedo * light;

        imageStore(framebufFinal, pix, vec4(color, 0));
    }
}


#if COMPUTE_SVGF_ATROUS_ITERATION_COUNT != 4
    #error Atrous is implemented for 4 iterations 
#endif